{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce7b6fc1-4ace-4077-b8ed-06d9df9d8377",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\flavi\\anaconda3\\envs\\meu_env_python3.11\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Importações necessárias\n",
    "import warnings\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import shap\n",
    "from reportlab.lib.pagesizes import letter\n",
    "from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, Image, Table, TableStyle\n",
    "from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle\n",
    "from reportlab.lib.units import inch\n",
    "import matplotlib.pyplot as plt\n",
    "import io\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55ade4fc-f8d4-4e53-9933-e99e88014940",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função auxiliar para converter figuras do Matplotlib em imagens para o PDF\n",
    "def fig_to_image(fig):\n",
    "    \"\"\"Converte uma figura matplotlib para um objeto Image do ReportLab\"\"\"\n",
    "    buf = io.BytesIO()\n",
    "    fig.savefig(buf, format='png', bbox_inches='tight', dpi=150)\n",
    "    buf.seek(0)\n",
    "    return Image(buf, width=6*inch, height=3*inch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24c91d82-75fd-4c70-9b4a-e5d09561e5fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função que realiza o pré-processamento da base de dados\n",
    "def load_and_preprocess_data(file_path):\n",
    "    \"\"\"Carrega e pré-processa os dados.\"\"\"\n",
    "    df = pd.read_parquet(file_path)\n",
    "    df = df[['Customer Name', 'Product ID', 'Product Name', 'Sales', 'Category', 'Sub-Category']].copy()\n",
    "\n",
    "    # Codificação\n",
    "    customer_encoder = LabelEncoder()\n",
    "    product_encoder = LabelEncoder()\n",
    "    category_encoder = LabelEncoder()\n",
    "    subcategory_encoder = LabelEncoder()\n",
    "\n",
    "    df['Customer ID Enc'] = customer_encoder.fit_transform(df['Customer Name'])\n",
    "    df['Product ID Enc'] = product_encoder.fit_transform(df['Product ID'])\n",
    "    df['Category Enc'] = category_encoder.fit_transform(df['Category'])\n",
    "    df['Sub-Category Enc'] = subcategory_encoder.fit_transform(df['Sub-Category'])\n",
    "\n",
    "    # Normalização\n",
    "    scaler = MinMaxScaler()\n",
    "    df['Sales Normalized'] = scaler.fit_transform(df[['Sales']])\n",
    "\n",
    "    return df, customer_encoder, product_encoder, category_encoder, subcategory_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80e84cc1-ab52-47e5-aa51-4f13f60e2402",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para dividir a base de dados em treino e teste\n",
    "def split_data(df):\n",
    "    \"\"\"Divide os dados em treino e teste.\"\"\"\n",
    "    customer_ids = df['Customer ID Enc'].values\n",
    "    product_ids = df['Product ID Enc'].values\n",
    "    category_ids = df['Category Enc'].values\n",
    "    subcategory_ids = df['Sub-Category Enc'].values\n",
    "    sales = df['Sales Normalized'].values\n",
    "\n",
    "    return train_test_split(\n",
    "        customer_ids, product_ids, category_ids, subcategory_ids, sales,\n",
    "        test_size=0.2, random_state=42\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c55a2493-a327-44ff-b710-0beec4ee32f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função que efetivamente cria o modelo de recomendação de produtos\n",
    "def create_model(num_customers, num_products, num_categories, num_subcategories, embedding_dim):\n",
    "    \"\"\"Cria o modelo de recomendação.\"\"\"\n",
    "    customer_input = layers.Input(shape=(1,), name='customer_input')\n",
    "    product_input = layers.Input(shape=(1,), name='product_input')\n",
    "    category_input = layers.Input(shape=(1,), name='category_input')\n",
    "    subcategory_input = layers.Input(shape=(1,), name='subcategory_input')\n",
    "\n",
    "    customer_embeddings = layers.Embedding(input_dim=num_customers, output_dim=embedding_dim, name='customer_embeddings')(customer_input)\n",
    "    product_embeddings = layers.Embedding(input_dim=num_products, output_dim=embedding_dim, name='product_embeddings')(product_input)\n",
    "    category_embeddings = layers.Embedding(input_dim=num_categories, output_dim=embedding_dim, name='category_embeddings')(category_input)\n",
    "    subcategory_embeddings = layers.Embedding(input_dim=num_subcategories, output_dim=embedding_dim, name='subcategory_embeddings')(subcategory_input)\n",
    "\n",
    "    customer_vec = layers.Flatten(name='customer_flatten')(customer_embeddings)\n",
    "    product_vec = layers.Flatten(name='product_flatten')(product_embeddings)\n",
    "    category_vec = layers.Flatten(name='category_flatten')(category_embeddings)\n",
    "    subcategory_vec = layers.Flatten(name='subcategory_flatten')(subcategory_embeddings)\n",
    "\n",
    "    concat_vec = layers.Concatenate(name='concat')([customer_vec, product_vec, category_vec, subcategory_vec])\n",
    "\n",
    "    dense_1 = layers.Dense(64, activation='relu', name='dense_1')(concat_vec)\n",
    "    dense_2 = layers.Dense(32, activation='relu', name='dense_2')(dense_1)\n",
    "    output = layers.Dense(1, activation='linear', name='output')(dense_2)\n",
    "\n",
    "    model = tf.keras.Model([customer_input, product_input, category_input, subcategory_input], output)\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='mse')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7fc4ddba-c368-44e3-beae-07cefb1a933e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função que treina o modelo de recomendação de produtos\n",
    "def train_model(model, customer_ids_train, product_ids_train, category_ids_train, subcategory_ids_train, sales_train, epochs=20, batch_size=32):\n",
    "    \"\"\"Treina o modelo.\"\"\"\n",
    "    model.fit(\n",
    "        [customer_ids_train, product_ids_train, category_ids_train, subcategory_ids_train],\n",
    "        sales_train,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        verbose=0\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "70424f48-8f32-4d08-8052-30dd8f5c1d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função já treinada que agora faz efetivamente a recomendação dos até 7 melhores produtos para o consumidor\n",
    "def recomendar_produtos(nome_cliente, df, model, customer_encoder, product_encoder, category_encoder, subcategory_encoder, top_k=7):\n",
    "    \"\"\"Retorna os top-k produtos recomendados para um cliente específico.\"\"\"\n",
    "    try:\n",
    "        cliente_id = customer_encoder.transform([nome_cliente])[0]\n",
    "    except ValueError:\n",
    "        cliente_id = -1\n",
    "\n",
    "    if cliente_id == -1:\n",
    "        sales_by_category = df.groupby(['Category', 'Product ID'])['Sales'].sum().reset_index()\n",
    "        recommended_products = pd.DataFrame()\n",
    "        for category in df['Category'].unique():\n",
    "            top_products = sales_by_category[sales_by_category['Category'] == category].nlargest(top_k, 'Sales')\n",
    "            recommended_products = pd.concat([recommended_products, top_products])\n",
    "\n",
    "        recommended_product_ids = recommended_products['Product ID'].unique()\n",
    "        valid_product_ids = [pid for pid in recommended_product_ids if pid in product_encoder.classes_]\n",
    "        \n",
    "        if not valid_product_ids:\n",
    "            top_products = df.nlargest(top_k, 'Sales')['Product ID'].unique()\n",
    "            valid_product_ids = [pid for pid in top_products if pid in product_encoder.classes_]\n",
    "            \n",
    "        if not valid_product_ids:\n",
    "            valid_product_ids = product_encoder.classes_[:top_k]\n",
    "            \n",
    "        recommended_products_names = product_encoder.inverse_transform(product_encoder.transform(valid_product_ids))\n",
    "        recommended_df = pd.DataFrame({'Product ID': recommended_products_names[:top_k]})\n",
    "        recommended_df = recommended_df.merge(df[['Product ID', 'Product Name', 'Category', 'Sub-Category']], on='Product ID', how='left').drop_duplicates()\n",
    "    else:\n",
    "        num_products = len(product_encoder.classes_)\n",
    "        product_ids = np.arange(num_products)\n",
    "        customer_ids = np.full((num_products,), cliente_id)\n",
    "        category_ids = np.zeros(num_products)\n",
    "        subcategory_ids = np.zeros(num_products)\n",
    "\n",
    "        product_scores = model.predict([customer_ids.reshape(-1, 1), product_ids.reshape(-1, 1), \n",
    "                                      category_ids.reshape(-1, 1), subcategory_ids.reshape(-1, 1)], \n",
    "                                     verbose=0).flatten()\n",
    "\n",
    "        top_product_indices = np.argsort(product_scores)[::-1]\n",
    "        recommended_products = []\n",
    "        categories_seen = set()\n",
    "        \n",
    "        i = 0\n",
    "        while len(recommended_products) < top_k and i < len(top_product_indices):\n",
    "            product_idx = top_product_indices[i]\n",
    "            product_id_encoded = product_encoder.classes_[product_idx]\n",
    "            product_category = df[df['Product ID Enc'] == product_idx]['Category'].iloc[0]\n",
    "            \n",
    "            if product_category not in categories_seen:\n",
    "                recommended_products.append(product_id_encoded)\n",
    "                categories_seen.add(product_category)\n",
    "            i += 1\n",
    "\n",
    "        if len(recommended_products) < top_k:\n",
    "            remaining_products = product_encoder.inverse_transform(top_product_indices[:top_k - len(recommended_products)])\n",
    "            recommended_products.extend(remaining_products)\n",
    "        recommended_products = recommended_products[:top_k]\n",
    "\n",
    "        recommended_df = pd.DataFrame({'Product ID': recommended_products})\n",
    "        recommended_df = recommended_df.merge(df[['Product ID', 'Product Name', 'Category', 'Sub-Category']], \n",
    "                                           on='Product ID', how='left').drop_duplicates()\n",
    "\n",
    "    recommended_df.insert(0, 'Ranking', range(1, len(recommended_df) + 1))\n",
    "    return recommended_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4cbad029-df0b-4d0a-b398-96b4b3dc02a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função que explica as recomendações (método SHAP)\n",
    "def explain_recommendations_shap(model, background_data, customer_id, product_id, category_id, subcategory_id):\n",
    "    \"\"\"Gera explicações SHAP para as recomendações.\"\"\"\n",
    "    def model_predict(X):\n",
    "        return model.predict([\n",
    "            X[:,0].reshape(-1,1),  # customer\n",
    "            X[:,1].reshape(-1,1),  # product\n",
    "            X[:,2].reshape(-1,1),  # category\n",
    "            X[:,3].reshape(-1,1)   # subcategory\n",
    "        ])\n",
    "    \n",
    "    explainer = shap.KernelExplainer(model_predict, background_data)\n",
    "    test_data = np.array([[customer_id, product_id, category_id, subcategory_id]])\n",
    "    shap_values = explainer.shap_values(test_data, l1_reg=\"aic\")\n",
    "    \n",
    "    return shap_values[0]  # Retorna apenas os valores para a primeira instância"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c13ff1a-04e2-402e-abc8-625c55a46ee8",
   "metadata": {},
   "source": [
    "### RELATÓRIO:\n",
    "Essa é a função que gera o relatório para a consumidora **Irene Maddox**. O modelo pode gerar relatórios para cada consumidor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2820c288-447a-4b0e-93eb-dcab07b54709",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                            | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  2.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                            | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  2.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                            | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  3.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                            | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  2.92it/s]\n"
     ]
    }
   ],
   "source": [
    "# Função para gerar relatórios SHAP a respeito das escolhas no algoritmo\n",
    "def gerar_relatorio_irene_maddox(df, model, customer_encoder, product_encoder, category_encoder, subcategory_encoder,\n",
    "                                customer_ids_train, product_ids_train, category_ids_train, subcategory_ids_train,\n",
    "                                file_path=\"relatorio_irene_maddox.pdf\"):\n",
    "    \"\"\"Gera um relatório em PDF com explicações SHAP para Irene Maddox.\"\"\"\n",
    "    \n",
    "    # Configuração do PDF\n",
    "    os.makedirs(os.path.dirname(file_path), exist_ok=True)\n",
    "    doc = SimpleDocTemplate(file_path, pagesize=letter)\n",
    "    styles = getSampleStyleSheet()\n",
    "    story = []\n",
    "    \n",
    "    # Estilos\n",
    "    h1_style = styles['h1']\n",
    "    h2_style = styles['h2']\n",
    "    normal_style = styles['Normal']\n",
    "    \n",
    "    # 1. Cabeçalho\n",
    "    story.append(Paragraph(\"Relatório de Interpretabilidade - Irene Maddox\", h1_style))\n",
    "    story.append(Paragraph(f\"Data: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\", normal_style))\n",
    "    story.append(Spacer(1, 0.5 * inch))\n",
    "    \n",
    "    # 2. Recomendações\n",
    "    story.append(Paragraph(\"Recomendações para Irene Maddox\", h2_style))\n",
    "    recomendacoes_df = recomendar_produtos(\"Irene Maddox\", df, model, customer_encoder, product_encoder, \n",
    "                                          category_encoder, subcategory_encoder)\n",
    "    \n",
    "    # Tabela de recomendações\n",
    "    data = [recomendacoes_df.columns.tolist()] + recomendacoes_df.values.tolist()\n",
    "    table = Table(data)\n",
    "    table.setStyle(TableStyle([('GRID', (0, 0), (-1, -1), 1, 'black'),\n",
    "                              ('FONTSIZE', (0, 0), (-1, -1), 8),\n",
    "                              ('VALIGN', (0, 0), (-1, -1), 'MIDDLE')]))\n",
    "    story.append(table)\n",
    "    story.append(Spacer(1, 0.5 * inch))\n",
    "    \n",
    "    # 3. Explicações SHAP\n",
    "    story.append(Paragraph(\"Explicação das Recomendações\", h2_style))\n",
    "    story.append(Paragraph(\"Esta seção explica como o modelo chegou a essas recomendações usando valores SHAP.\", normal_style))\n",
    "    story.append(Spacer(1, 0.2 * inch))\n",
    "    \n",
    "    # Preparar dados para SHAP\n",
    "    cliente_id = customer_encoder.transform([\"Irene Maddox\"])[0]\n",
    "    \n",
    "    # Amostrar dados de background\n",
    "    background_size = min(100, len(customer_ids_train))\n",
    "    background_indices = np.random.choice(len(customer_ids_train), size=background_size, replace=False)\n",
    "    background_data = np.column_stack([\n",
    "        customer_ids_train[background_indices],\n",
    "        product_ids_train[background_indices],\n",
    "        category_ids_train[background_indices],\n",
    "        subcategory_ids_train[background_indices]\n",
    "    ])\n",
    "    \n",
    "    # Gerar explicações SHAP para os produtos recomendados\n",
    "    recommended_product_indices = [product_encoder.transform([pid])[0] for pid in recomendacoes_df['Product ID']]\n",
    "    \n",
    "    for i, product_idx in enumerate(recommended_product_indices[:5]):  # Analisar apenas os 5 primeiros para o relatório\n",
    "        product_id = recomendacoes_df.iloc[i]['Product ID']\n",
    "        product_name = recomendacoes_df.iloc[i]['Product Name']\n",
    "        \n",
    "        story.append(Paragraph(f\"Produto {i+1}: {product_name} ({product_id})\", h2_style))\n",
    "        \n",
    "        # Obter valores SHAP para este produto específico\n",
    "        shap_values = explain_recommendations_shap(\n",
    "            model, background_data,\n",
    "            cliente_id, product_idx, 0, 0\n",
    "        )\n",
    "        \n",
    "        # Gráfico de importância das features\n",
    "        feature_names = ['Customer', 'Product', 'Category', 'Subcategory']\n",
    "        shap_values = np.array(shap_values).flatten()\n",
    "        \n",
    "        fig, ax = plt.subplots(figsize=(10, 6))\n",
    "        shap.bar_plot(shap_values, feature_names=feature_names, show=False)\n",
    "        ax.set_title(f'Contribuição das Features', pad=20)\n",
    "        ax.set_xlabel('Valor SHAP', labelpad=10)\n",
    "        ax.tick_params(axis='both', which='major', labelsize=10)\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        story.append(fig_to_image(fig))\n",
    "        story.append(Spacer(1, 0.2 * inch))\n",
    "        \n",
    "        # Explicação textual\n",
    "        explanation = (\n",
    "            f\"Este gráfico mostra como cada característica contribuiu para a recomendação deste produto. \"\n",
    "            f\"Valores SHAP positivos indicam que a característica aumentou a probabilidade de recomendação, \"\n",
    "            f\"enquanto valores negativos diminuíram.\"\n",
    "        )\n",
    "        story.append(Paragraph(explanation, normal_style))\n",
    "        story.append(Spacer(1, 0.5 * inch))\n",
    "        \n",
    "        plt.close(fig)\n",
    "    \n",
    "    doc.build(story)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Caminho para os dados\n",
    "    from src.config import DADOS_TRATADOS\n",
    "    file_path = DADOS_TRATADOS\n",
    "    \n",
    "    # Caminho para o PDF\n",
    "    pdf_file_path = r\"C:\\Users\\flavi\\Documents\\GitHub\\Projeto_7_Sistema_de_Recomendacao\\Notebooks\\relatorio_irene_maddox.pdf\"\n",
    "    \n",
    "    # Carregar e pré-processar os dados\n",
    "    df, customer_encoder, product_encoder, category_encoder, subcategory_encoder = load_and_preprocess_data(file_path)\n",
    "    \n",
    "    # Dividir os dados\n",
    "    (customer_ids_train, customer_ids_test,\n",
    "     product_ids_train, product_ids_test,\n",
    "     category_ids_train, category_ids_test,\n",
    "     subcategory_ids_train, subcategory_ids_test,\n",
    "     sales_train, sales_test) = split_data(df)\n",
    "    \n",
    "    # Criar e treinar o modelo\n",
    "    num_customers = len(customer_encoder.classes_)\n",
    "    num_products = len(product_encoder.classes_)\n",
    "    num_categories = len(category_encoder.classes_)\n",
    "    num_subcategories = len(subcategory_encoder.classes_)\n",
    "    embedding_dim = 50\n",
    "    \n",
    "    model = create_model(num_customers, num_products, num_categories, num_subcategories, embedding_dim)\n",
    "    model = train_model(model, customer_ids_train, product_ids_train, category_ids_train, subcategory_ids_train, sales_train)\n",
    "    \n",
    "    # Gerar relatório específico para Irene Maddox\n",
    "    gerar_relatorio_irene_maddox(df, model, customer_encoder, product_encoder, category_encoder, subcategory_encoder,\n",
    "                                customer_ids_train, product_ids_train, category_ids_train, subcategory_ids_train,\n",
    "                                pdf_file_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11 (TensorFlow)",
   "language": "python",
   "name": "meu_env_python3.11"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
