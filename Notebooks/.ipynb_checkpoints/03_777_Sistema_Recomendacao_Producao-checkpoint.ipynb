{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e504241f-8f5a-4485-9bc3-b41841c09865",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importações\n",
    "\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from collections import defaultdict\n",
    "import os\n",
    "from datetime import datetime\n",
    "from tensorflow.keras.metrics import MeanSquaredError "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aac9b461-7ff5-4aa2-a996-776c018497c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Carregamento e Pré-processamento dos Dados ---\n",
    "\n",
    "def load_and_preprocess_data(file_path):\n",
    "    \"\"\"Carrega e pré-processa os dados.\"\"\"\n",
    "\n",
    "    df = pd.read_parquet(file_path)\n",
    "    df = df[['Customer Name', 'Product ID', 'Product Name', 'Sales', 'Category', 'Sub-Category']].copy()\n",
    "\n",
    "    # Codificação\n",
    "    customer_encoder = LabelEncoder()\n",
    "    product_encoder = LabelEncoder()\n",
    "    category_encoder = LabelEncoder()\n",
    "    subcategory_encoder = LabelEncoder()\n",
    "\n",
    "    df['Customer ID Enc'] = customer_encoder.fit_transform(df['Customer Name'])\n",
    "    df['Product ID Enc'] = product_encoder.fit_transform(df['Product ID'])\n",
    "    df['Category Enc'] = category_encoder.fit_transform(df['Category'])\n",
    "    df['Sub-Category Enc'] = subcategory_encoder.fit_transform(df['Sub-Category'])\n",
    "\n",
    "    # Normalização\n",
    "    scaler = MinMaxScaler()\n",
    "    df['Sales Normalized'] = scaler.fit_transform(df[['Sales']])\n",
    "\n",
    "    return df, customer_encoder, product_encoder, category_encoder, subcategory_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f19b365c-95d1-4011-8756-02cd9b240cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Divisão dos Dados ---\n",
    "\n",
    "def split_data(df):\n",
    "    \"\"\"Divide os dados em treino e teste.\"\"\"\n",
    "\n",
    "    customer_ids = df['Customer ID Enc'].values\n",
    "    product_ids = df['Product ID Enc'].values\n",
    "    category_ids = df['Category Enc'].values\n",
    "    subcategory_ids = df['Sub-Category Enc'].values\n",
    "    sales = df['Sales Normalized'].values\n",
    "\n",
    "    customer_ids_train, customer_ids_test, \\\n",
    "    product_ids_train, product_ids_test, \\\n",
    "    category_ids_train, category_ids_test, \\\n",
    "    subcategory_ids_train, subcategory_ids_test, \\\n",
    "    sales_train, sales_test = train_test_split(\n",
    "        customer_ids, product_ids, category_ids, subcategory_ids, sales,\n",
    "        test_size=0.2, random_state=42\n",
    "    )\n",
    "\n",
    "    return (customer_ids_train, customer_ids_test,\n",
    "            product_ids_train, product_ids_test,\n",
    "            category_ids_train, category_ids_test,\n",
    "            subcategory_ids_train, subcategory_ids_test,\n",
    "            sales_train, sales_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9472cbff-bb01-495a-be22-c1d313f7b73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Modelo ---\n",
    "\n",
    "def create_model(num_customers, num_products, num_categories, num_subcategories, embedding_dim):\n",
    "    \"\"\"Cria o modelo de recomendação.\"\"\"\n",
    "\n",
    "    customer_input = layers.Input(shape=(1,), name='customer_input')\n",
    "    product_input = layers.Input(shape=(1,), name='product_input')\n",
    "    category_input = layers.Input(shape=(1,), name='category_input')\n",
    "    subcategory_input = layers.Input(shape=(1,), name='subcategory_input')\n",
    "\n",
    "    customer_embeddings = layers.Embedding(input_dim=num_customers, output_dim=embedding_dim, name='customer_embeddings')(customer_input)\n",
    "    product_embeddings = layers.Embedding(input_dim=num_products, output_dim=embedding_dim, name='product_embeddings')(product_input)\n",
    "    category_embeddings = layers.Embedding(input_dim=num_categories, output_dim=embedding_dim, name='category_embeddings')(category_input)\n",
    "    subcategory_embeddings = layers.Embedding(input_dim=num_subcategories, output_dim=embedding_dim, name='subcategory_embeddings')(subcategory_input)\n",
    "\n",
    "    customer_vec = layers.Flatten(name='customer_flatten')(customer_embeddings)\n",
    "    product_vec = layers.Flatten(name='product_flatten')(product_embeddings)\n",
    "    category_vec = layers.Flatten(name='category_flatten')(category_embeddings)\n",
    "    subcategory_vec = layers.Flatten(name='subcategory_flatten')(subcategory_embeddings)\n",
    "\n",
    "    concat_vec = layers.Concatenate(name='concat')([customer_vec, product_vec, category_vec, subcategory_vec])\n",
    "\n",
    "    dense_1 = layers.Dense(64, activation='relu', name='dense_1')(concat_vec)\n",
    "    dense_2 = layers.Dense(32, activation='relu', name='dense_2')(dense_1)\n",
    "    output = layers.Dense(1, activation='linear', name='output')(dense_2)\n",
    "\n",
    "    model = tf.keras.Model([customer_input, product_input, category_input, subcategory_input], output)\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='mse')  # Otimizador Adam e taxa de aprendizado padrão\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "64d13444-d5af-4393-b731-17b3c2de41bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Métricas de Avaliação ---\n",
    "\n",
    "def evaluate_model(model, customer_ids, product_ids, category_ids, subcategory_ids, sales, top_k=7):\n",
    "    \"\"\"Avalia o modelo usando MSE e métricas de recomendação (precisão@k, recall@k, F1@k).\"\"\"\n",
    "\n",
    "    predictions = model.predict([customer_ids, product_ids, category_ids, subcategory_ids], verbose=0).flatten()\n",
    "    #mse = tf.keras.metrics.mean_squared_error(sales, predictions).numpy()  #  <--  Remova esta linha\n",
    "    mse_calculator = MeanSquaredError()  # Crie uma instância da métrica\n",
    "    mse = mse_calculator(sales, predictions).numpy()  # Calcule o MSE usando a instância\n",
    "\n",
    "    # Métricas de recomendação\n",
    "    relevant_items = defaultdict(list)\n",
    "    recommended_items = defaultdict(list)\n",
    "\n",
    "    for i in range(len(customer_ids)):\n",
    "        customer = customer_ids[i]\n",
    "        true_sale = sales[i]\n",
    "        prediction = predictions[i]\n",
    "\n",
    "        if true_sale > 0.5:  # Define o limiar para relevância (ajuste conforme necessário)\n",
    "            relevant_items[customer].append((product_ids[i], true_sale))\n",
    "\n",
    "        recommended_items[customer].append((product_ids[i], prediction))\n",
    "\n",
    "    precision_at_k_sum = 0\n",
    "    recall_at_k_sum = 0\n",
    "    f1_at_k_sum = 0\n",
    "    num_users_with_relevant_items = 0\n",
    "\n",
    "    for customer in relevant_items:\n",
    "        if len(relevant_items[customer]) > 0:\n",
    "            num_users_with_relevant_items += 1\n",
    "            # Sort recommended items by prediction score for this customer\n",
    "            recommended_items[customer].sort(key=lambda x: x[1], reverse=True)\n",
    "            top_k_recommended = [item[0] for item in recommended_items[customer][:top_k]]\n",
    "            \n",
    "            relevant_set = {item[0] for item in relevant_items[customer]}\n",
    "            \n",
    "            hits = len(relevant_set.intersection(top_k_recommended))\n",
    "            precision = hits / top_k if top_k else 0\n",
    "            recall = hits / len(relevant_set) if len(relevant_set) > 0 else 0\n",
    "            f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "            \n",
    "            precision_at_k_sum += precision\n",
    "            recall_at_k_sum += recall\n",
    "            f1_at_k_sum += f1\n",
    "\n",
    "    avg_precision_at_k = precision_at_k_sum / num_users_with_relevant_items if num_users_with_relevant_items > 0 else 0\n",
    "    avg_recall_at_k = recall_at_k_sum / num_users_with_relevant_items if num_users_with_relevant_items > 0 else 0\n",
    "    avg_f1_at_k = f1_at_k_sum / num_users_with_relevant_items if num_users_with_relevant_items > 0 else 0\n",
    "\n",
    "    return mse, avg_precision_at_k, avg_recall_at_k, avg_f1_at_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2d6460b-c1f7-421d-b0ea-2851e7b446f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Função de Recomendação ---\n",
    "\n",
    "def recomendar_produtos(nome_cliente, df, model, customer_encoder, product_encoder, category_encoder, subcategory_encoder, top_k=7):\n",
    "    \"\"\"\n",
    "    Retorna os top-k produtos recomendados para um cliente específico,\n",
    "    lidando com o cold start e considerando diversidade básica.\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        cliente_id = customer_encoder.transform([nome_cliente])[0]\n",
    "    except ValueError:\n",
    "        # Cliente não encontrado (Cold Start)\n",
    "        cliente_id = -1\n",
    "\n",
    "    if cliente_id == -1:\n",
    "        # Estratégia de Cold Start: Produtos mais vendidos por categoria\n",
    "        # Calcula as vendas por categoria\n",
    "        sales_by_category = df.groupby(['Category', 'Product ID'])['Sales'].sum().reset_index()\n",
    "\n",
    "        # Para cada categoria, obtém os top-k produtos mais vendidos\n",
    "        recommended_products = pd.DataFrame()\n",
    "        for category in df['Category'].unique():\n",
    "            top_products = sales_by_category[sales_by_category['Category'] == category].nlargest(top_k, 'Sales')\n",
    "            recommended_products = pd.concat([recommended_products, top_products])\n",
    "\n",
    "        # Decodifica os IDs dos produtos\n",
    "        recommended_product_ids = recommended_products['Product ID'].unique()\n",
    "        recommended_products_names = product_encoder.inverse_transform(recommended_product_ids)\n",
    "\n",
    "        recommended_df = pd.DataFrame({'Product ID': recommended_products_names})\n",
    "        recommended_df = recommended_df.merge(df[['Product ID', 'Product Name', 'Category', 'Sub-Category']], on='Product ID', how='left').drop_duplicates()\n",
    "\n",
    "    else:\n",
    "        # Cliente conhecido: Prever pontuações\n",
    "        num_products = len(product_encoder.classes_)\n",
    "        product_ids = np.arange(num_products)\n",
    "        customer_ids = np.full((num_products,), cliente_id)\n",
    "        category_ids = np.zeros(num_products)  # Usando 0 como placeholder\n",
    "        subcategory_ids = np.zeros(num_products)  # Usando 0 como placeholder\n",
    "\n",
    "\n",
    "        product_scores = model.predict([customer_ids.reshape(-1, 1), product_ids.reshape(-1, 1), category_ids.reshape(-1, 1), subcategory_ids.reshape(-1, 1)], verbose=0).flatten()\n",
    "\n",
    "        # Obter os top-k produtos recomendados com diversidade básica\n",
    "        # (Seleciona um pouco de cada categoria, se possível)\n",
    "        top_product_indices = np.argsort(product_scores)[::-1]\n",
    "        recommended_products = []\n",
    "        categories_seen = set()\n",
    "        \n",
    "        i = 0\n",
    "        while len(recommended_products) < top_k and i < len(top_product_indices):\n",
    "            product_idx = top_product_indices[i]\n",
    "            product_id_encoded = product_encoder.classes_[product_idx]\n",
    "            product_category = df[df['Product ID Enc'] == product_idx]['Category'].iloc[0] #Pegar a categoria do produto original\n",
    "            \n",
    "            if product_category not in categories_seen:\n",
    "                recommended_products.append(product_id_encoded)\n",
    "                categories_seen.add(product_category)\n",
    "            i += 1\n",
    "\n",
    "        # Se não conseguiu diversificar totalmente, preenche com os melhores restantes\n",
    "        if len(recommended_products) < top_k:\n",
    "            remaining_products = product_encoder.inverse_transform(top_product_indices[:top_k - len(recommended_products)])\n",
    "            recommended_products.extend(remaining_products)\n",
    "            recommended_products = recommended_products[:top_k]  # Garante que não ultrapassa top_k\n",
    "\n",
    "        recommended_df = pd.DataFrame({'Product ID': recommended_products})\n",
    "        recommended_df = recommended_df.merge(df[['Product ID', 'Product Name', 'Category', 'Sub-Category']], on='Product ID', how='left').drop_duplicates()\n",
    "\n",
    "    recommended_df.insert(0, 'Ranking', range(1, len(recommended_df) + 1))\n",
    "    return recommended_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "86089bfd-d581-498f-98a9-61973f346ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Treinamento e Avaliação ---\n",
    "\n",
    "def train_and_evaluate(df, customer_encoder, product_encoder, category_encoder, subcategory_encoder, epochs=20, batch_size=32):\n",
    "    \"\"\"Treina e avalia o modelo.\"\"\"\n",
    "\n",
    "    (customer_ids_train, customer_ids_test,\n",
    "     product_ids_train, product_ids_test,\n",
    "     category_ids_train, category_ids_test,\n",
    "     subcategory_ids_train, subcategory_ids_test,\n",
    "     sales_train, sales_test) = split_data(df)\n",
    "\n",
    "    num_customers = len(customer_encoder.classes_)\n",
    "    num_products = len(product_encoder.classes_)\n",
    "    num_categories = len(category_encoder.classes_)\n",
    "    num_subcategories = len(subcategory_encoder.classes_)\n",
    "    embedding_dim = 16  # Ajuste conforme necessário\n",
    "\n",
    "    model = create_model(num_customers, num_products, num_categories, num_subcategories, embedding_dim)\n",
    "\n",
    "    # Callbacks (TensorBoard)\n",
    "    log_dir = \"logs/fit/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "    model.fit(\n",
    "        [customer_ids_train.reshape(-1, 1), product_ids_train.reshape(-1, 1), category_ids_train.reshape(-1, 1), subcategory_ids_train.reshape(-1, 1)],\n",
    "        sales_train,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        verbose=1,\n",
    "        callbacks=[tensorboard_callback]\n",
    "    )\n",
    "\n",
    "    # Avaliação\n",
    "    mse_train, precision_train, recall_train, f1_train = evaluate_model(\n",
    "        model, customer_ids_train, product_ids_train, category_ids_train, subcategory_ids_train, sales_train\n",
    "    )\n",
    "    mse_test, precision_test, recall_test, f1_test = evaluate_model(\n",
    "        model, customer_ids_test, product_ids_test, category_ids_test, subcategory_ids_test, sales_test\n",
    "    )\n",
    "\n",
    "    print(f\"Treino: MSE = {mse_train:.4f}, Precision@{7} = {precision_train:.4f}, Recall@{7} = {recall_train:.4f}, F1@{7} = {f1_train:.4f}\")\n",
    "    print(f\"Teste: MSE = {mse_test:.4f}, Precision@{7} = {precision_test:.4f}, Recall@{7} = {recall_test:.4f}, F1@{7} = {f1_test:.4f}\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "56964204-e59b-439f-903b-5e86f51bcdd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m245/245\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 5.8160e-04\n",
      "Epoch 2/20\n",
      "\u001b[1m245/245\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 2.9534e-04\n",
      "Epoch 3/20\n",
      "\u001b[1m245/245\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 1.7096e-04\n",
      "Epoch 4/20\n",
      "\u001b[1m245/245\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 9.6492e-05\n",
      "Epoch 5/20\n",
      "\u001b[1m245/245\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 6.2686e-05\n",
      "Epoch 6/20\n",
      "\u001b[1m245/245\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 7.1874e-05\n",
      "Epoch 7/20\n",
      "\u001b[1m245/245\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 3.5738e-05\n",
      "Epoch 8/20\n",
      "\u001b[1m245/245\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 4.0905e-05\n",
      "Epoch 9/20\n",
      "\u001b[1m245/245\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 3.4382e-05\n",
      "Epoch 10/20\n",
      "\u001b[1m245/245\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 3.6730e-05\n",
      "Epoch 11/20\n",
      "\u001b[1m245/245\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 4.2628e-05\n",
      "Epoch 12/20\n",
      "\u001b[1m245/245\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 2.8158e-05\n",
      "Epoch 13/20\n",
      "\u001b[1m245/245\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 2.2265e-05\n",
      "Epoch 14/20\n",
      "\u001b[1m245/245\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 2.0710e-05\n",
      "Epoch 15/20\n",
      "\u001b[1m245/245\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 2.0797e-05\n",
      "Epoch 16/20\n",
      "\u001b[1m245/245\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 1.9202e-05\n",
      "Epoch 17/20\n",
      "\u001b[1m245/245\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 1.6594e-05\n",
      "Epoch 18/20\n",
      "\u001b[1m245/245\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 2.7459e-05\n",
      "Epoch 19/20\n",
      "\u001b[1m245/245\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 3.1369e-05\n",
      "Epoch 20/20\n",
      "\u001b[1m245/245\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 2.3586e-05\n",
      "Treino: MSE = 0.0000, Precision@7 = 0.1429, Recall@7 = 1.0000, F1@7 = 0.2500\n",
      "Teste: MSE = 0.0008, Precision@7 = 0.1429, Recall@7 = 1.0000, F1@7 = 0.2500\n"
     ]
    }
   ],
   "source": [
    "# --- Main ---\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Caminho para os dados \n",
    "    from src.config import DADOS_TRATADOS  # Importe a variável do seu arquivo de configuração\n",
    "    file_path = DADOS_TRATADOS\n",
    "\n",
    "    # Carregar e pré-processar os dados\n",
    "    df, customer_encoder, product_encoder, category_encoder, subcategory_encoder = load_and_preprocess_data(file_path)\n",
    "\n",
    "    # Treinar e avaliar o modelo\n",
    "    trained_model = train_and_evaluate(df, customer_encoder, product_encoder, category_encoder, subcategory_encoder)\n",
    "\n",
    "    # Gerar recomendações para um cliente específico\n",
    "    cliente_para_recomendar = \"Irene Maddox\"  # Escolha o cliente\n",
    "    recomendacoes = recomendar_produtos(cliente_para_recomendar, df, trained_model, customer_encoder, product_encoder, category_encoder, subcategory_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e93df36f-2589-4341-aceb-d734d0be5df3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Recomendações para Irene Maddox:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ranking</th>\n",
       "      <th>Product ID</th>\n",
       "      <th>Product Name</th>\n",
       "      <th>Category</th>\n",
       "      <th>Sub-Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>TEC-CO-10004722</td>\n",
       "      <td>Canon imageCLASS 2200 Advanced Copier</td>\n",
       "      <td>Technology</td>\n",
       "      <td>Copiers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>OFF-SU-10000151</td>\n",
       "      <td>High Speed Automatic Electric Letter Opener</td>\n",
       "      <td>Office Supplies</td>\n",
       "      <td>Supplies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>FUR-CH-10002024</td>\n",
       "      <td>HON 5400 Series Task Chairs for Big and Tall</td>\n",
       "      <td>Furniture</td>\n",
       "      <td>Chairs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>4</td>\n",
       "      <td>TEC-MA-10001127</td>\n",
       "      <td>HP Designjet T520 Inkjet Large Format Printer ...</td>\n",
       "      <td>Technology</td>\n",
       "      <td>Machines</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>5</td>\n",
       "      <td>OFF-BI-10000545</td>\n",
       "      <td>GBC Ibimaster 500 Manual ProClick Binding System</td>\n",
       "      <td>Office Supplies</td>\n",
       "      <td>Binders</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Ranking       Product ID  \\\n",
       "0         1  TEC-CO-10004722   \n",
       "5         2  OFF-SU-10000151   \n",
       "8         3  FUR-CH-10002024   \n",
       "24        4  TEC-MA-10001127   \n",
       "27        5  OFF-BI-10000545   \n",
       "\n",
       "                                         Product Name         Category  \\\n",
       "0               Canon imageCLASS 2200 Advanced Copier       Technology   \n",
       "5         High Speed Automatic Electric Letter Opener  Office Supplies   \n",
       "8        HON 5400 Series Task Chairs for Big and Tall        Furniture   \n",
       "24  HP Designjet T520 Inkjet Large Format Printer ...       Technology   \n",
       "27   GBC Ibimaster 500 Manual ProClick Binding System  Office Supplies   \n",
       "\n",
       "   Sub-Category  \n",
       "0       Copiers  \n",
       "5      Supplies  \n",
       "8        Chairs  \n",
       "24     Machines  \n",
       "27      Binders  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"\\nRecomendações para {cliente_para_recomendar}:\\n\")\n",
    "recomendacoes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11 (TensorFlow)",
   "language": "python",
   "name": "meu_env_python3.11"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
